"""
Video Analyzer using Google Gemini API
Sprint 2: E-Com Video Insider
"""

import os
import json
import time
import tempfile
import subprocess
import requests
import yt_dlp
from pathlib import Path
from typing import Dict, Optional, List
import google.generativeai as genai
from openai import OpenAI
from dotenv import load_dotenv

from .prompts import VIDEO_ANALYSIS_SYSTEM_PROMPT

# Load environment variables
load_dotenv()


class VideoAnalyzer:
    """
    è§†é¢‘å†…å®¹åˆ†æå™¨
    ä½¿ç”¨ Google Gemini 1.5 Pro API åˆ†æçŸ­è§†é¢‘ç»“æ„å¹¶ç”Ÿæˆç¿»æ‹å»ºè®®
    """
    
    def __init__(self, api_key: Optional[str] = None, api_base: Optional[str] = None):
        """
        åˆå§‹åŒ– Video Analyzer
        
        Args:
            api_key: Google Gemini API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            api_base: è‡ªå®šä¹‰ API Base URLï¼ˆç”¨äº KIE API ç­‰ä»£ç†æœåŠ¡ï¼‰
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.api_base = api_base or os.getenv('GEMINI_API_BASE')
        
        # å¦‚æœä½¿ç”¨ KIE APIï¼Œå¯èƒ½ä¸éœ€è¦å•ç‹¬çš„ API Keyï¼ˆè®¤è¯ä¿¡æ¯åŒ…å«åœ¨ URL ä¸­ï¼‰
        if not self.api_key and not self.api_base:
            raise ValueError("GEMINI_API_KEY æˆ– GEMINI_API_BASE è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ª")
        
        # å¦‚æœæ²¡æœ‰ API Key ä½†æœ‰ API Baseï¼Œä½¿ç”¨ä¸€ä¸ªé»˜è®¤å€¼
        if not self.api_key and self.api_base:
            self.api_key = "dummy_key_for_kie_api"  # KIE API å¯èƒ½ä¸éœ€è¦çœŸå®çš„ key
        
        # é…ç½® Gemini API
        if self.api_base:
            # ä½¿ç”¨è‡ªå®šä¹‰ API Base URLï¼ˆKIE APIï¼‰
            genai.configure(
                api_key=self.api_key,
                transport='rest',
                client_options={'api_endpoint': self.api_base}
            )
            print(f"âœ… ä½¿ç”¨è‡ªå®šä¹‰ API Base: {self.api_base}")
        else:
            # ä½¿ç”¨é»˜è®¤ Google API
            genai.configure(api_key=self.api_key)
            print("âœ… ä½¿ç”¨ Google å®˜æ–¹ API")
        
        # ä½¿ç”¨ Gemini 1.5 Proï¼ˆæ›´å¼ºçš„è§†é¢‘ç†è§£èƒ½åŠ›ï¼‰
        # Pro ç‰ˆæœ¬åœ¨è§†é¢‘åˆ†æä»»åŠ¡ä¸Šå‡†ç¡®æ€§æ›´é«˜ï¼Œå‡å°‘å¹»è§‰
        # æ³¨æ„: ç§»é™¤ system_instruction ä»¥å…¼å®¹ Google AI Studio çš„ç¨³å®šç‰ˆ API (v1)
        self.model = genai.GenerativeModel(
            model_name='gemini-1.5-pro-latest',
            generation_config={
                'temperature': 0.3,  # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
            }
        )
        
        # ä¿å­˜ç³»ç»Ÿæç¤ºè¯ï¼Œç¨åä¸ç”¨æˆ·æç¤ºè¯ç»„åˆä½¿ç”¨
        self.system_prompt = VIDEO_ANALYSIS_SYSTEM_PROMPT
        
        # ä¸´æ—¶æ–‡ä»¶å¤¹ï¼ˆä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ï¼Œå…¼å®¹ Streamlit Cloudï¼‰
        self.temp_dir = Path(tempfile.gettempdir()) / 'ecom_video_insider'
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äº Whisper APIï¼‰
        openai_key = os.getenv('OPENAI_API_KEY')
        openai_base = os.getenv('OPENAI_API_BASE')  # æ”¯æŒç¬¬ä¸‰æ–¹ä»£ç†
        
        if openai_key:
            # å¦‚æœæœ‰è‡ªå®šä¹‰ base_urlï¼Œä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†
            if openai_base:
                self.openai_client = OpenAI(
                    api_key=openai_key,
                    base_url=openai_base.strip()  # å»é™¤å¯èƒ½çš„ç©ºæ ¼
                )
                print(f"âœ… OpenAI Whisper API å·²å¯ç”¨ï¼ˆä½¿ç”¨ä»£ç†: {openai_base})")
            else:
                self.openai_client = OpenAI(api_key=openai_key)
                print("âœ… OpenAI Whisper API å·²å¯ç”¨ï¼ˆå®˜æ–¹ APIï¼‰")
        else:
            self.openai_client = None
            print("âš ï¸ OpenAI API Key æœªé…ç½®ï¼Œå°†ä½¿ç”¨ Gemini è¿›è¡Œè½¬å½•")
    
    def download_video_with_ytdlp(self, video_url: str) -> str:
        """
        ä½¿ç”¨ yt-dlp ä» TikTok/Instagram/YouTube ä¸‹è½½è§†é¢‘
        
        Args:
            video_url: TikTok/Instagram/YouTube è§†é¢‘ URL
            
        Returns:
            æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“¥ ä½¿ç”¨ yt-dlp ä¸‹è½½è§†é¢‘: {video_url}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = int(time.time())
        output_template = str(self.temp_dir / f"video_{timestamp}.%(ext)s")
        
        # yt-dlp é…ç½®
        ydl_opts = {
            'format': 'best[ext=mp4]/best',  # ä¼˜å…ˆä¸‹è½½ mp4 æ ¼å¼
            'outtmpl': output_template,
            'quiet': False,
            'no_warnings': False,
            'extract_flat': False,
            'nocheckcertificate': True,
            # YouTube ç‰¹å®šé…ç½®ï¼ˆç»•è¿‡ 403 é”™è¯¯ï¼‰
            'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'referer': 'https://www.youtube.com/',
            'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # ä¸‹è½½è§†é¢‘
                info = ydl.extract_info(video_url, download=True)
                
                # è·å–å®é™…ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
                filename = ydl.prepare_filename(info)
                
                print(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {filename}")
                return filename
                
        except Exception as e:
            print(f"âŒ yt-dlp ä¸‹è½½å¤±è´¥: {str(e)}")
            raise ValueError(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {str(e)}")
    
    def download_video(self, video_url: str, output_filename: Optional[str] = None) -> str:
        """
        ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶å¤¹ï¼ˆå…¼å®¹æ—§çš„ç›´æ¥ä¸‹è½½é“¾æ¥æ–¹å¼ï¼‰
        
        Args:
            video_url: è§†é¢‘ä¸‹è½½é“¾æ¥
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
            
        Returns:
            æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘: {video_url}")
        
        if not output_filename:
            # ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = int(time.time())
            output_filename = f"video_{timestamp}.mp4"
        
        output_path = self.temp_dir / output_filename
        
        try:
            # ä¸‹è½½è§†é¢‘
            response = requests.get(video_url, stream=True, timeout=60)
            response.raise_for_status()
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            print(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {output_path}")
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {str(e)}")
            raise
    
    def upload_to_gemini(self, video_path: str, max_wait_time: int = 300):
        """
        ä¸Šä¼ è§†é¢‘åˆ° Gemini API å¹¶ç­‰å¾…å¤„ç†å®Œæˆ
        
        Args:
            video_path: æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 300 ç§’
            
        Returns:
            Gemini File å¯¹è±¡
        """
        print(f"â˜ï¸  å¼€å§‹ä¸Šä¼ è§†é¢‘åˆ° Gemini API: {video_path}")
        
        try:
            # ä¸Šä¼ æ–‡ä»¶
            video_file = genai.upload_file(path=video_path)
            print(f"âœ… è§†é¢‘ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶å: {video_file.name}")
            print(f"â³ ç­‰å¾… Gemini å¤„ç†è§†é¢‘...")
            
            # å…³é”®ï¼šç­‰å¾…æ–‡ä»¶çŠ¶æ€å˜ä¸º ACTIVE
            start_time = time.time()
            while video_file.state.name == "PROCESSING":
                elapsed_time = time.time() - start_time
                
                if elapsed_time > max_wait_time:
                    raise TimeoutError(f"è§†é¢‘å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡ {max_wait_time} ç§’ï¼‰")
                
                print(f"  çŠ¶æ€: {video_file.state.name}ï¼Œå·²ç­‰å¾… {int(elapsed_time)} ç§’...")
                time.sleep(5)  # æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡
                video_file = genai.get_file(video_file.name)
            
            if video_file.state.name == "FAILED":
                raise ValueError(f"è§†é¢‘å¤„ç†å¤±è´¥: {video_file.state.name}")
            
            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼ŒçŠ¶æ€: {video_file.state.name}")
            return video_file
            
        except Exception as e:
            print(f"âŒ è§†é¢‘ä¸Šä¼ æˆ–å¤„ç†å¤±è´¥: {str(e)}")
            raise
    
    def extract_audio(self, video_path: str) -> str:
        """
        ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸµ æå–éŸ³é¢‘: {video_path}")
        
        audio_path = str(Path(video_path).with_suffix('.mp3'))
        
        try:
            # ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘
            subprocess.run([
                'ffmpeg', '-i', video_path,
                '-vn',  # ä¸å¤„ç†è§†é¢‘
                '-acodec', 'libmp3lame',  # ä½¿ç”¨ MP3 ç¼–ç 
                '-ar', '16000',  # 16kHz é‡‡æ ·ç‡ï¼ˆé€‚åˆ ASRï¼‰
                '-ac', '1',  # å•å£°é“
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                audio_path
            ], check=True, capture_output=True)
            
            print(f"âœ… éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
            return audio_path
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e.stderr.decode()}")
            raise ValueError(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
    
    def transcribe_audio_with_whisper(self, audio_path: str) -> List[Dict]:
        """
        ä½¿ç”¨ OpenAI Whisper API è¿›è¡ŒéŸ³é¢‘è½¬å½•ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬å½•ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼: [{"timestamp": "00:00", "text": "..."}]
            å¦‚æœå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
        """
        print(f"ğŸ¤ ä½¿ç”¨ Whisper API è¿›è¡Œè¯­éŸ³è½¬å½•: {audio_path}")
        
        try:
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(audio_path):
                print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                return []
            
            # è°ƒç”¨ Whisper API
            print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ éŸ³é¢‘åˆ° Whisper API...")
            with open(audio_path, 'rb') as audio_file:
                response = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json",  # è·å–å¸¦æ—¶é—´æˆ³çš„è¯¦ç»†ç»“æœ
                    timestamp_granularities=["segment"]  # æŒ‰å¥å­/æ®µè½åˆ†æ®µ
                )
            
            print(f"âœ… Whisper API è½¬å½•æˆåŠŸ")
            
            # è§£æ Whisper å“åº”
            transcript = []
            if hasattr(response, 'segments') and response.segments:
                for segment in response.segments:
                    # å°†ç§’è½¬æ¢ä¸º MM:SS æ ¼å¼
                    start_time = int(segment['start'])
                    minutes = start_time // 60
                    seconds = start_time % 60
                    timestamp = f"{minutes:02d}:{seconds:02d}"
                    
                    transcript.append({
                        "timestamp": timestamp,
                        "text": segment['text'].strip()
                    })
                
                print(f"âœ… è½¬å½•å®Œæˆï¼Œå…± {len(transcript)} æ¡è®°å½•")
                for item in transcript[:3]:  # æ‰“å°å‰3æ¡
                    print(f"  [{item['timestamp']}] {item['text'][:50]}...")
            else:
                # å¦‚æœæ²¡æœ‰ segmentsï¼Œä½¿ç”¨æ•´ä½“æ–‡æœ¬
                if hasattr(response, 'text') and response.text:
                    transcript.append({
                        "timestamp": "00:00",
                        "text": response.text.strip()
                    })
                    print(f"âœ… è½¬å½•å®Œæˆï¼ˆæ— æ—¶é—´æˆ³åˆ†æ®µï¼‰")
                else:
                    print("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹")
            
            return transcript
            
        except Exception as e:
            print(f"âŒ Whisper è½¬å½•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def transcribe_audio(self, audio_path: str) -> List[Dict]:
        """
        éŸ³é¢‘è½¬å½•ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•ï¼‰
        
        ä¼˜å…ˆä½¿ç”¨ OpenAI Whisper APIï¼ˆæ›´å‡†ç¡®ï¼‰ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ Gemini
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬å½•ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼: [{"timestamp": "00:00", "text": "..."}]
        """
        # ä¼˜å…ˆä½¿ç”¨ Whisper API
        if self.openai_client:
            transcript = self.transcribe_audio_with_whisper(audio_path)
            if transcript:  # å¦‚æœæˆåŠŸï¼Œç›´æ¥è¿”å›
                return transcript
            print("âš ï¸ Whisper è½¬å½•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ Gemini...")
        
        # å¤‡é€‰ï¼šä½¿ç”¨ Gemini
        return self.transcribe_audio_with_gemini(audio_path)
    def transcribe_audio_with_gemini(self, audio_path: str) -> List[Dict]:
        """
        ä½¿ç”¨ Gemini API è¿›è¡ŒéŸ³é¢‘è½¬å½•ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬å½•ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼: [{"timestamp": "00:00", "text": "..."}]
            å¦‚æœå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
        """
        print(f"ğŸ¬ å¼€å§‹è¯­éŸ³è½¬å½•: {audio_path}")
        
        try:
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(audio_path):
                print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                return []
            
            # ä¸Šä¼ éŸ³é¢‘åˆ° Gemini
            print(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ éŸ³é¢‘...")
            audio_file = genai.upload_file(path=audio_path)
            print(f"âœ… éŸ³é¢‘ä¸Šä¼ æˆåŠŸ: {audio_file.name}")
            
            # ç­‰å¾…å¤„ç†
            max_wait = 30  # æœ€å¤šç­‰å¾… 30 ç§’
            wait_count = 0
            while audio_file.state.name == "PROCESSING" and wait_count < max_wait:
                time.sleep(1)
                audio_file = genai.get_file(audio_file.name)
                wait_count += 1
            
            if audio_file.state.name == "PROCESSING":
                print("âŒ éŸ³é¢‘å¤„ç†è¶…æ—¶")
                return []
            
            print(f"âœ… éŸ³é¢‘å¤„ç†å®Œæˆï¼ŒçŠ¶æ€: {audio_file.state.name}")
            
            # è°ƒç”¨ Gemini è¿›è¡Œè½¬å½•
            prompt = """è¯·å¬è¿™æ®µéŸ³é¢‘ï¼Œå¹¶å°†å…¶ä¸­çš„è¯­éŸ³å†…å®¹è½¬å½•ä¸ºæ–‡å­—ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼š
```json
{
  "transcript": [
    {"timestamp": "00:00", "text": "ç¬¬ä¸€å¥è¯çš„å†…å®¹"},
    {"timestamp": "00:05", "text": "ç¬¬äºŒå¥è¯çš„å†…å®¹"}
  ]
}
```

æ³¨æ„ï¼š
1. æ—¶é—´æˆ³æ ¼å¼ä¸º MM:SS
2. æ¯ 5-10 ç§’åˆ†ä¸€æ®µ
3. ä¿æŒåŸå§‹è¯­è¨€
4. å¦‚æœæ²¡æœ‰è¯­éŸ³ï¼Œè¿”å›ç©ºæ•°ç»„
5. åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š"""
            
            print("ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini API è¿›è¡Œè½¬å½•...")
            response = self.model.generate_content([audio_file, prompt])
            response_text = response.text.strip()
            
            print(f"ğŸ“ Gemini å“åº”: {response_text[:200]}...")  # æ‰“å°å‰ 200 å­—ç¬¦
            
            # è§£æ JSON
            transcript = []
            try:
                # å°è¯•ç›´æ¥è§£æ
                result = json.loads(response_text)
                transcript = result.get('transcript', [])
                print(f"âœ… JSON è§£ææˆåŠŸï¼Œå…± {len(transcript)} æ¡è®°å½•")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æå¤±è´¥: {str(e)}ï¼Œå°è¯•æå–...")
                # æå– JSON ä»£ç å—
                import re
                json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', response_text, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group(1))
                    transcript = result.get('transcript', [])
                    print(f"âœ… ä»ä»£ç å—æå–æˆåŠŸï¼Œå…± {len(transcript)} æ¡è®°å½•")
                else:
                    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}')
                    if start_idx != -1 and end_idx != -1:
                        json_str = response_text[start_idx:end_idx+1]
                        try:
                            result = json.loads(json_str)
                            transcript = result.get('transcript', [])
                            print(f"âœ… æ‰‹åŠ¨æå–æˆåŠŸï¼Œå…± {len(transcript)} æ¡è®°å½•")
                        except:
                            print("âŒ æ— æ³•è§£ææå–çš„ JSON")
                    else:
                        print("âŒ å“åº”ä¸­æœªæ‰¾åˆ° JSON æ ¼å¼")
            
            # éªŒè¯è½¬å½•ç»“æœ
            if transcript and len(transcript) > 0:
                # è¿‡æ»¤æ‰é”™è¯¯ä¿¡æ¯
                valid_transcript = [t for t in transcript if 'è½¬å½•å¤±è´¥' not in t.get('text', '')]
                if valid_transcript:
                    print(f"âœ… è½¬å½•æˆåŠŸï¼Œå…± {len(valid_transcript)} æ¡æœ‰æ•ˆè®°å½•")
                    return valid_transcript
            
            print("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹")
            return []
            
        except Exception as e:
            print(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def analyze_video_structure(self, video_url: str, cleanup: bool = True) -> Dict:
        """
        å®Œæ•´çš„è§†é¢‘åˆ†ææµç¨‹
        
        Args:
            video_url: è§†é¢‘ä¸‹è½½é“¾æ¥ï¼ˆæ¥è‡ª Sprint 1 çš„ TikTokFetcherï¼‰
            cleanup: æ˜¯å¦åœ¨åˆ†æååˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œé»˜è®¤ True
            
        Returns:
            åŒ…å«è§†é¢‘åˆ†æç»“æœçš„å­—å…¸ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
            {
                'video_metadata': {...},
                'structure_breakdown': {...},
                'creative_insight': {...},
                'lazada_adaptation_brief': {...}
            }
        """
        print("=" * 60)
        print("ğŸ¬ å¼€å§‹è§†é¢‘ç»“æ„åˆ†æ")
        print("=" * 60)
        
        local_video_path = None
        
        try:
            # æ­¥éª¤ 1: ä¸‹è½½è§†é¢‘
            local_video_path = self.download_video(video_url)
            
            # æ­¥éª¤ 2: ä¸Šä¼ åˆ° Gemini å¹¶ç­‰å¾…å¤„ç†
            video_file = self.upload_to_gemini(local_video_path)
            
            # æ­¥éª¤ 3: è°ƒç”¨ Gemini API è¿›è¡Œåˆ†æ
            print("ğŸ¤– å¼€å§‹ AI åˆ†æ...")
            
            # ç»„åˆç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
            # å› ä¸º Google AI Studio API (v1) ä¸æ”¯æŒ system_instruction
            combined_prompt = f"""{self.system_prompt}

---

Now, please analyze the following video according to the framework above.
Return your analysis in valid JSON format.
"""
            
            response = self.model.generate_content([video_file, combined_prompt])
            
            # æ­¥éª¤ 4: è§£æ JSON å“åº”
            try:
                analysis_result = json.loads(response.text)
                print("âœ… åˆ†æå®Œæˆï¼")
                
                # æ‰“å°å…³é”®ä¿¡æ¯
                self._print_analysis_summary(analysis_result)
                
                return analysis_result
                
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
                print(f"åŸå§‹å“åº”: {response.text}")
                raise ValueError(f"Gemini è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSON: {e}")
            
        except Exception as e:
            print(f"âŒ è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            raise
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if cleanup and local_video_path and os.path.exists(local_video_path):
                try:
                    os.remove(local_video_path)
                    print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {local_video_path}")
                except Exception as e:
                    print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_analysis_summary(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœæ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†æç»“æœæ‘˜è¦")
        print("=" * 60)
        
        # è§†é¢‘å…ƒæ•°æ®
        metadata = analysis.get('video_metadata', {})
        print(f"\nğŸ¥ è§†é¢‘å…ƒæ•°æ®:")
        print(f"  è¯­è¨€: {metadata.get('primary_language', 'N/A')}")
        print(f"  æƒ…æ„Ÿ: {metadata.get('estimated_sentiment', 'N/A')}")
        
        # ç»“æ„æ‹†è§£
        structure = analysis.get('structure_breakdown', {})
        print(f"\nğŸ¯ ç»“æ„æ‹†è§£:")
        print(f"  Hook ç±»å‹: {structure.get('hook_type', 'N/A')}")
        print(f"  ç—›ç‚¹: {structure.get('pain_point_addressed', 'N/A')}")
        print(f"  äº§å“å‡ºç°æ—¶é—´: {structure.get('product_reveal_timestamp', 'N/A')}")
        print(f"  æ ¸å¿ƒå–ç‚¹: {structure.get('key_selling_proposition', 'N/A')}")
        
        # åˆ›æ„æ´å¯Ÿ
        insight = analysis.get('creative_insight', {})
        print(f"\nğŸ’¡ åˆ›æ„æ´å¯Ÿ:")
        print(f"  è§†è§‰é£æ ¼: {insight.get('visual_style', 'N/A')}")
        print(f"  ä¸ºä»€ä¹ˆæœ‰æ•ˆ: {insight.get('why_it_works', 'N/A')[:80]}...")
        
        # Lazada ç¿»æ‹å»ºè®®
        adaptation = analysis.get('lazada_adaptation_brief', {})
        print(f"\nğŸ¬ Lazada ç¿»æ‹å»ºè®®:")
        print(f"  ç¿»æ‹éš¾åº¦: {adaptation.get('remake_difficulty', 'N/A')}")
        print(f"  æœ¬åœ°åŒ–å»ºè®®: {adaptation.get('localization_tip', 'N/A')[:80]}...")
        
        print("=" * 60 + "\n")


def main():
    """
    æµ‹è¯•å‡½æ•° - ä½¿ç”¨ Mock Data æ¨¡æ‹Ÿæµç¨‹
    """
    print("=" * 60)
    print("Video Analyzer - Sprint 2 æµ‹è¯•")
    print("=" * 60)
    
    # Mock Data æ¨¡å¼æµ‹è¯•
    print("\nğŸ“‹ æ¨¡å¼: Mock Data æµ‹è¯•")
    mock_analysis = {
        "video_metadata": {
            "primary_language": "English",
            "estimated_sentiment": "Positive"
        },
        "structure_breakdown": {
            "hook_type": "Visual Shock",
            "hook_description": "Split screen showing before/after transformation with dramatic zoom",
            "pain_point_addressed": "Dirty, stained surfaces that are hard to clean",
            "product_reveal_timestamp": "00:05",
            "key_selling_proposition": "Effortless cleaning in seconds"
        },
        "creative_insight": {
            "why_it_works": "Uses satisfying transformation visual that triggers dopamine response",
            "visual_style": "UGC with high production value"
        },
        "lazada_adaptation_brief": {
            "remake_difficulty": "Medium",
            "script_template": "1. Show dirty surface close-up 2. Apply product with satisfying sound 3. Reveal clean result 4. Show price and CTA",
            "localization_tip": "Emphasize cash-on-delivery option and add local language subtitles"
        }
    }
    
    print("\nâœ¨ Mock åˆ†æç»“æœç¤ºä¾‹:")
    print(json.dumps(mock_analysis, indent=2, ensure_ascii=False))
    
    print("\n" + "=" * 60)
    print("ğŸ’¡ æç¤º: è¦æµ‹è¯•çœŸå® APIï¼Œè¯·:")
    print("  1. ç¡®ä¿ .env ä¸­å·²é…ç½® GEMINI_API_KEY")
    print("  2. å‡†å¤‡ä¸€ä¸ªè§†é¢‘ä¸‹è½½é“¾æ¥")
    print("  3. å–æ¶ˆä¸‹æ–¹ä»£ç æ³¨é‡Šå¹¶è¿è¡Œ")
    print("=" * 60)
    
    # çœŸå® API æµ‹è¯•ï¼ˆé»˜è®¤æ³¨é‡Šï¼‰
    """
    # å–æ¶ˆæ³¨é‡Šä»¥æµ‹è¯•çœŸå® API
    try:
        analyzer = VideoAnalyzer()
        
        # ä½¿ç”¨ Sprint 1 è·å–çš„è§†é¢‘ä¸‹è½½é“¾æ¥
        video_download_url = "https://example.com/video.mp4"  # æ›¿æ¢ä¸ºçœŸå® URL
        
        result = analyzer.analyze_video_structure(video_download_url)
        
        print("\nğŸ‰ çœŸå® API æµ‹è¯•ç»“æœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
    """


if __name__ == "__main__":
    main()
